### 2.1 网络爬虫基础（5分钟）

#### 什么是网络爬虫？

**网络爬虫**就像是一个自动化的美食侦探，它的任务是从互联网上“抓取”各种美食信息。想象一下，你非常喜欢美食，想要收集所有关于美食的资料，比如餐厅的菜单、食谱、美食评论等等。但是，互联网上有无数的网页，手动去收集这些信息几乎是不可能的。这时候，网络爬虫就派上用场了！

##### 网络爬虫的工作流程

1. **发送请求**：首先，爬虫会向目标网站发送一个请求，就像你走进一家餐厅，询问他们的菜单。
2. **获取响应**：网站会返回一个响应，就像餐厅的服务员把菜单递给你。
3. **解析数据**：爬虫会解析这个响应，提取出有用的信息，就像你仔细阅读菜单，找到你感兴趣的菜品。
4. **存储数据**：最后，爬虫会把这些信息存储起来，方便你以后查看，就像你把菜单上的菜品记录在一个笔记本上。

#### 类比解释

- **发送请求**：想象你走进一家餐厅，对服务员说：“请给我一份菜单。”
- **获取响应**：服务员递给你一份菜单。
- **解析数据**：你仔细阅读菜单，找到你想点的菜品。
- **存储数据**：你把菜单上的菜品记录在一个笔记本上，方便以后查看。

#### 网络爬虫的工作流程图

```mermaid
graph LR
    A[发送请求] --> B[获取响应]
    B --> C[解析数据]
    C --> D[存储数据]
```

#### 练习

1. **理解爬虫的工作流程**：请用自己的话描述网络爬虫的工作流程，并尝试用一个你感兴趣的例子（比如收集电影信息）来解释这个流程。

2. **编写一个简单的爬虫**：使用Python编写一个简单的爬虫，从某个网站上抓取你感兴趣的美食信息。你可以使用`requests`库来发送请求，使用`BeautifulSoup`库来解析数据。

   ```python
   import requests
   from bs4 import BeautifulSoup

   # 发送请求
   url = "https://example.com/menu"
   response = requests.get(url)

   # 获取响应
   html_content = response.text

   # 解析数据
   soup = BeautifulSoup(html_content, 'html.parser')
   menu_items = soup.find_all('div', class_='menu-item')

   # 存储数据
   for item in menu_items:
       print(item.text)
   ```

   请尝试修改代码，抓取你感兴趣的美食信息，并将其存储在一个文件中。

---

通过这个简单的练习，你将能够更好地理解网络爬虫的工作原理，并开始动手编写自己的爬虫程序。
