{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mytools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "请你扮演网络爬取数据领域的教学专家，我是一个编程基础薄弱的学生，请按照我的要求，为我生成教学大纲：\n",
    "\n",
    "要求：\n",
    "\n",
    "1. 教学内容不要太多，能在1小时内学完。\n",
    "2. 我的兴趣是美食\n",
    "3. 我已经基本掌握Python语法基础\n",
    "\n",
    "'''\n",
    "result = mytools.dsllm(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 教学大纲：1小时学会用Python爬取美食网站数据\n",
      "\n",
      "#### 1. 课程目标\n",
      "- 了解网络爬虫的基本概念。\n",
      "- 学会使用Python进行简单的网页数据爬取。\n",
      "- 能够从美食网站上爬取并保存感兴趣的美食信息。\n",
      "\n",
      "#### 2. 课程内容\n",
      "\n",
      "##### 2.1 网络爬虫基础（5分钟）\n",
      "- **什么是网络爬虫？**\n",
      "  - 网络爬虫是一种自动化程序，用于从互联网上抓取数据。\n",
      "  - 爬虫的工作流程：发送请求 -> 获取响应 -> 解析数据 -> 存储数据。\n",
      "\n",
      "##### 2.2 安装必要的Python库（5分钟）\n",
      "- **安装Requests库**\n",
      "  - `pip install requests`\n",
      "- **安装BeautifulSoup库**\n",
      "  - `pip install beautifulsoup4`\n",
      "\n",
      "##### 2.3 发送HTTP请求（10分钟）\n",
      "- **使用Requests库发送GET请求**\n",
      "  - 示例代码：\n",
      "    ```python\n",
      "    import requests\n",
      "\n",
      "    url = \"https://www.example-food-website.com\"\n",
      "    response = requests.get(url)\n",
      "    print(response.text)\n",
      "    ```\n",
      "  - 解释：如何发送请求并获取网页的HTML内容。\n",
      "\n",
      "##### 2.4 解析HTML内容（15分钟）\n",
      "- **使用BeautifulSoup解析HTML**\n",
      "  - 示例代码：\n",
      "    ```python\n",
      "    from bs4 import BeautifulSoup\n",
      "\n",
      "    soup = BeautifulSoup(response.text, 'html.parser')\n",
      "    title = soup.find('title').text\n",
      "    print(title)\n",
      "    ```\n",
      "  - 解释：如何使用BeautifulSoup解析HTML并提取特定标签的内容。\n",
      "\n",
      "##### 2.5 爬取美食信息（15分钟）\n",
      "- **爬取美食网站上的美食名称和描述**\n",
      "  - 示例代码：\n",
      "    ```python\n",
      "    food_items = soup.find_all('div', class_='food-item')\n",
      "    for item in food_items:\n",
      "        name = item.find('h2').text\n",
      "        description = item.find('p').text\n",
      "        print(f\"Name: {name}, Description: {description}\")\n",
      "    ```\n",
      "  - 解释：如何定位并提取美食名称和描述。\n",
      "\n",
      "##### 2.6 保存数据到文件（10分钟）\n",
      "- **将爬取的数据保存到CSV文件**\n",
      "  - 示例代码：\n",
      "    ```python\n",
      "    import csv\n",
      "\n",
      "    with open('food_data.csv', 'w', newline='') as file:\n",
      "        writer = csv.writer(file)\n",
      "        writer.writerow([\"Name\", \"Description\"])\n",
      "        for item in food_items:\n",
      "            name = item.find('h2').text\n",
      "            description = item.find('p').text\n",
      "            writer.writerow([name, description])\n",
      "    ```\n",
      "  - 解释：如何将爬取的数据保存到CSV文件中。\n",
      "\n",
      "#### 3. 总结与练习（5分钟）\n",
      "- **总结**\n",
      "  - 回顾本节课的主要内容：发送请求、解析HTML、提取数据、保存数据。\n",
      "- **练习**\n",
      "  - 尝试爬取另一个美食网站的数据，并保存到文件中。\n",
      "\n",
      "#### 4. 课后作业\n",
      "- **作业**\n",
      "  - 选择一个你感兴趣的美食网站，尝试爬取更多信息（如价格、评分等），并保存到CSV文件中。\n",
      "\n",
      "---\n",
      "\n",
      "通过这个教学大纲，你将能够在1小时内掌握基本的网络爬虫技术，并能够应用于你感兴趣的美食领域。\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 2.1 网络爬虫基础（5分钟）\n",
      "\n",
      "#### 什么是网络爬虫？\n",
      "\n",
      "**网络爬虫**就像是一个自动化的美食侦探，它的任务是从互联网上“抓取”各种美食信息。想象一下，你非常喜欢美食，想要收集所有关于美食的资料，比如餐厅的菜单、食谱、美食评论等等。但是，互联网上有无数的网页，手动去收集这些信息几乎是不可能的。这时候，网络爬虫就派上用场了！\n",
      "\n",
      "##### 网络爬虫的工作流程\n",
      "\n",
      "1. **发送请求**：首先，爬虫会向目标网站发送一个请求，就像你走进一家餐厅，询问他们的菜单。\n",
      "2. **获取响应**：网站会返回一个响应，就像餐厅的服务员把菜单递给你。\n",
      "3. **解析数据**：爬虫会解析这个响应，提取出有用的信息，就像你仔细阅读菜单，找到你感兴趣的菜品。\n",
      "4. **存储数据**：最后，爬虫会把这些信息存储起来，方便你以后查看，就像你把菜单上的菜品记录在一个笔记本上。\n",
      "\n",
      "#### 类比解释\n",
      "\n",
      "- **发送请求**：想象你走进一家餐厅，对服务员说：“请给我一份菜单。”\n",
      "- **获取响应**：服务员递给你一份菜单。\n",
      "- **解析数据**：你仔细阅读菜单，找到你想点的菜品。\n",
      "- **存储数据**：你把菜单上的菜品记录在一个笔记本上，方便以后查看。\n",
      "\n",
      "#### 网络爬虫的工作流程图\n",
      "\n",
      "```mermaid\n",
      "graph LR\n",
      "    A[发送请求] --> B[获取响应]\n",
      "    B --> C[解析数据]\n",
      "    C --> D[存储数据]\n",
      "```\n",
      "\n",
      "#### 练习\n",
      "\n",
      "1. **理解爬虫的工作流程**：请用自己的话描述网络爬虫的工作流程，并尝试用一个你感兴趣的例子（比如收集电影信息）来解释这个流程。\n",
      "\n",
      "2. **编写一个简单的爬虫**：使用Python编写一个简单的爬虫，从某个网站上抓取你感兴趣的美食信息。你可以使用`requests`库来发送请求，使用`BeautifulSoup`库来解析数据。\n",
      "\n",
      "   ```python\n",
      "   import requests\n",
      "   from bs4 import BeautifulSoup\n",
      "\n",
      "   # 发送请求\n",
      "   url = \"https://example.com/menu\"\n",
      "   response = requests.get(url)\n",
      "\n",
      "   # 获取响应\n",
      "   html_content = response.text\n",
      "\n",
      "   # 解析数据\n",
      "   soup = BeautifulSoup(html_content, 'html.parser')\n",
      "   menu_items = soup.find_all('div', class_='menu-item')\n",
      "\n",
      "   # 存储数据\n",
      "   for item in menu_items:\n",
      "       print(item.text)\n",
      "   ```\n",
      "\n",
      "   请尝试修改代码，抓取你感兴趣的美食信息，并将其存储在一个文件中。\n",
      "\n",
      "---\n",
      "\n",
      "通过这个简单的练习，你将能够更好地理解网络爬虫的工作原理，并开始动手编写自己的爬虫程序。\n"
     ]
    }
   ],
   "source": [
    "outline = '''\n",
    "##### 2.1 网络爬虫基础（5分钟）\n",
    "- **什么是网络爬虫？**\n",
    "  - 网络爬虫是一种自动化程序，用于从互联网上抓取数据。\n",
    "  - 爬虫的工作流程：发送请求 -> 获取响应 -> 解析数据 -> 存储数据。\n",
    "'''\n",
    "\n",
    "prompt = f'''\n",
    "请你扮演网络爬取数据领域的教学专家，我是一个编程基础薄弱的学生，请按照教学大纲<outline>{outline}</outline>，生成详细的教学内容。\n",
    "\n",
    "要求：\n",
    "\n",
    "1. 教学内容通俗易懂，对关键概念进行类比式的解释；\n",
    "2. 我的兴趣是美食；\n",
    "3. 我已经基本掌握Python语法基础；\n",
    "4. 内容要有练习，但不要有答案。\n",
    "5. 能使用表格(markdown)、思维导图(mermaid)、概念图(mermaid)的地方尽量使用\n",
    "'''\n",
    "result = mytools.dsllm(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！以下是“大纲”这个词的英语翻译及相关信息：\n",
      "\n",
      "**英语翻译：** Outline\n",
      "\n",
      "**音标：** /ˈaʊt.laɪn/\n",
      "\n",
      "**例句：**\n",
      "- **Before writing the essay, I created an outline to organize my thoughts.**\n",
      "  （在写论文之前，我创建了一个大纲来整理我的思路。）\n",
      "\n",
      "希望这对你有帮助！如果你有其他问题，随时问我。\n"
     ]
    }
   ],
   "source": [
    "print(mytools.en('大纲'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
